{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinKaras(AI)\\.conda\\envs\\n_body_approx_3_10\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from utils import segnn_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from datasets.nbody.dataset_gravity import GravityDataset\n",
    "\n",
    "sys.argv = [\n",
    "    'main.py', '--dataset=gravity', '--epochs=5', '--max_samples=3000',\n",
    "    '--model=segnn', '--lmax_h=1', '--lmax_attr=1', '--layers=4',\n",
    "    '--hidden_features=64', '--subspace_type=weightbalanced', '--norm=none',\n",
    "    '--batch_size=100', '--gpu=1', '--weight_decay=1e-12', '--target=pos'\n",
    "]\n",
    "parser = segnn_utils.create_argparser()\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(sys.executable)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "run = os.path.join(\"segnn_runs\", \"2024-03-18 18-38_gravityV2_segnn\")\n",
    "\n",
    "models = glob.glob(run + \"/\" + '*.pth')\n",
    "if len(models) > 1:\n",
    "    print(\"MORE MODELS FOUND IN THE DIR, LOADING THE FIRST:\", models[0])\n",
    "\n",
    "model = torch.load(models[0], map_location=device)\n",
    "\n",
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:37:03.057105Z",
     "start_time": "2024-03-19T10:36:58.942762Z"
    }
   },
   "id": "49eba1514facfe10",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting prediction from batches, where a batch is all steps of a single simulation\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9cacda1635bda3c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinKaras(AI)\\.conda\\envs\\n_body_approx_3_10\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "simulation_index = 0\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "output_dims = loc.shape[-1]\n",
    "batch_size = loc.shape[-3]\n",
    "n_nodes = loc.shape[-2]\n",
    "\n",
    "t_delta = 2\n",
    "\n",
    "loc = torch.from_numpy(loc[simulation_index]).view(-1, output_dims)\n",
    "vel = torch.from_numpy(vel[simulation_index]).view(-1, output_dims)\n",
    "force = torch.from_numpy(force[simulation_index]).view(-1, output_dims)\n",
    "mass = torch.from_numpy(mass[simulation_index]).repeat(batch_size, 1)\n",
    "data = [loc, vel, force, mass]\n",
    "\n",
    "if args.target == 'pos':\n",
    "    y = loc\n",
    "else:\n",
    "    y = force\n",
    "\n",
    "data = [d.to(device) for d in data]\n",
    "loc, vel, force, mass = data\n",
    "\n",
    "graph = Data(pos=loc, vel=vel, force=force, mass=mass, y=y)\n",
    "batch = torch.arange(0, batch_size)\n",
    "graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "\n",
    "graph = transform(graph)  # Add O3 attributes\n",
    "graph = graph.to(device)\n",
    "batch_prediction = model(graph).cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:37:04.487746Z",
     "start_time": "2024-03-19T10:37:03.059107Z"
    }
   },
   "id": "784c2d52f9547f57",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot the whole simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1987cd9c25d516e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "article_index = None\n",
    "boxSize = 5\n",
    "model_output_dims = batch_prediction.shape[-1]\n",
    "\n",
    "loc_orig = loc.view(batch_size, n_nodes, output_dims)\n",
    "predicted_position_changes = batch_prediction.reshape(batch_size, n_nodes, model_output_dims)[..., :output_dims]\n",
    "predicted_positions = loc_orig + predicted_position_changes\n",
    "\n",
    "targets = []\n",
    "for i in range(0, batch_size - t_delta):\n",
    "    targets.append(loc_orig[i + t_delta, :, :])\n",
    "\n",
    "targets_np = np.array(targets)\n",
    "\n",
    "dataset_train.simulation.interactive_trajectory_plot_all_particles_3d(targets_np, predicted_positions,\n",
    "                                                                      None,\n",
    "                                                                      boxSize=boxSize, dims=output_dims,\n",
    "                                                                      offline_plot=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:37:05.784524Z",
     "start_time": "2024-03-19T10:37:04.488745Z"
    }
   },
   "id": "5deb9d99498406f2",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# !!! SELF FEED PREDICTION !!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b593518ba0c6d9ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "output_dims = loc.shape[-1]\n",
    "n_nodes = loc.shape[-2]\n",
    "\n",
    "n_sims = 10\n",
    "num_steps = 6\n",
    "\n",
    "t_delta = 2\n",
    "\n",
    "loc = torch.from_numpy(loc)\n",
    "vel = torch.from_numpy(vel)\n",
    "force = torch.from_numpy(force)\n",
    "mass = torch.from_numpy(mass)\n",
    "\n",
    "# get just initial states\n",
    "loc, vel, force, mass = [d[:n_sims, 0, ...].to(device) for d in [loc, vel, force, mass]]\n",
    "loc, vel, force = [d.reshape(-1, 3) for d in [loc, vel, force]]\n",
    "mass = mass.repeat(n_nodes, 1)\n",
    "loc_orig = loc.clone()\n",
    "\n",
    "simulation_instance = dataset_train.simulation\n",
    "\n",
    "states = []\n",
    "self_feed_predictions = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    batch = torch.arange(0, n_sims)\n",
    "    graph = Data(pos=loc, vel=vel, force=force, mass=mass)\n",
    "    \n",
    "    graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "    graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "    graph = transform(graph)  # Add O3 attributes\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    # Model prediction\n",
    "    prediction = model(graph).cpu().detach().numpy()\n",
    "\n",
    "    # Update states based on prediction\n",
    "    delta_loc, delta_vel = prediction[:, :output_dims], prediction[:, output_dims:]\n",
    "\n",
    "    # Update position and velocity\n",
    "    loc = loc + torch.from_numpy(delta_loc).to(device)\n",
    "    vel = vel + torch.from_numpy(delta_vel).to(device)\n",
    "\n",
    "    force = simulation_instance.compute_force_batched(loc.cpu().detach().numpy(), mass.cpu().detach().numpy(),\n",
    "                                                      simulation_instance.interaction_strength,\n",
    "                                                      simulation_instance.softening, batch_size)\n",
    "\n",
    "    force = torch.from_numpy(force)\n",
    "\n",
    "    states.append((loc.clone(), vel.clone(), force.clone()))\n",
    "    self_feed_predictions.append(loc.clone().view(n_nodes, n_sims, output_dims))\n",
    "\n",
    "self_feed_predictions = np.array(self_feed_predictions)\n",
    "#self_feed_predictions = self_feed_predictions.transpose(1, 0 ,2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:06:00.862211Z",
     "start_time": "2024-03-19T12:06:00.633316Z"
    }
   },
   "id": "b37cd89863491fb4",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "simulation_index = 0\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "output_dims = loc.shape[-1]\n",
    "n_nodes = loc.shape[-2]\n",
    "t_delta = 2\n",
    "\n",
    "# Assuming simulation_steps is defined or calculated from your dataset\n",
    "simulation_steps = len(loc[simulation_index])  # Or however you determine the number of steps\n",
    "stepwise_prediction = []\n",
    "for step in range(simulation_steps):\n",
    "    loc_step = torch.from_numpy(loc[simulation_index][step]).view(-1, output_dims).to(device)\n",
    "    vel_step = torch.from_numpy(vel[simulation_index][step]).view(-1, output_dims).to(device)\n",
    "    force_step = torch.from_numpy(force[simulation_index][step]).view(-1, output_dims).to(device)\n",
    "    mass_step = torch.tensor(mass[simulation_index], dtype=torch.float).repeat(n_nodes, 1).to(device)\n",
    "\n",
    "    if args.target == 'pos':\n",
    "        y_step = loc_step\n",
    "    else:\n",
    "        y_step = force_step\n",
    "\n",
    "    graph = Data(pos=loc_step, vel=vel_step, force=force_step, mass=mass_step, y=y_step)\n",
    "    # Since we're dealing with single steps, no need to batch\n",
    "    graph.edge_index = knn_graph(loc_step, args.neighbours)\n",
    "\n",
    "    graph = transform(graph)  # Add O3 attributes\n",
    "    graph = graph.to(device)\n",
    "    stepwise_prediction.append(model(graph).detach().numpy())\n",
    "\n",
    "stepwise_prediction = np.stack(stepwise_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:09:38.501844Z",
     "start_time": "2024-03-19T12:09:37.600595Z"
    }
   },
   "id": "5a998e45bc566eea",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "self_feed_predictions.transpose(1, )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2409d4cb5f8123e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7500 into shape (50,5,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m num_sims \u001B[38;5;241m=\u001B[39m self_feed_predictions\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      6\u001B[0m loc_orig \u001B[38;5;241m=\u001B[39m loc_orig\u001B[38;5;241m.\u001B[39mview(batch_size, n_nodes, output_dims)\n\u001B[1;32m----> 7\u001B[0m predicted_positions_self_feed \u001B[38;5;241m=\u001B[39m \u001B[43mself_feed_predictions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_output_dims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m targets \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, batch_size \u001B[38;5;241m-\u001B[39m t_delta):\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 7500 into shape (50,5,3)"
     ]
    }
   ],
   "source": [
    "particle_index = None\n",
    "boxSize = 5\n",
    "model_output_dims = self_feed_predictions.shape[-1]\n",
    "num_sims = self_feed_predictions.shape[0]\n",
    "\n",
    "loc_orig = loc_orig.view(batch_size, n_nodes, output_dims)\n",
    "predicted_positions_self_feed = self_feed_predictions.reshape(batch_size, n_nodes, model_output_dims)\n",
    "\n",
    "targets = []\n",
    "for i in range(0, batch_size - t_delta):\n",
    "    targets.append(loc_orig[i + t_delta, :, :])\n",
    "\n",
    "targets_np = np.array(targets)\n",
    "\n",
    "dataset_train.simulation.interactive_trajectory_plot_all_particles_3d(targets_np, predicted_positions_self_feed,\n",
    "                                                                      None,\n",
    "                                                                      boxSize=boxSize, dims=output_dims,\n",
    "                                                                      offline_plot=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T11:25:28.929443Z",
     "start_time": "2024-03-19T11:25:28.896869Z"
    }
   },
   "id": "95a4e265896f9630",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(250, 6)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction.reshape(batch_size, n_nodes, output_dims)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T08:56:14.046995Z",
     "start_time": "2024-03-19T08:56:14.036365Z"
    }
   },
   "id": "e0ece3c561ced98",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interactive plot of the simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82efe104f68292eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnbody\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_gravity\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdataset_gravity\u001B[39;00m\n\u001B[0;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mimportlib\u001B[49m\u001B[38;5;241m.\u001B[39mreload(dataset_gravity)\n\u001B[0;32m      5\u001B[0m dataset_train \u001B[38;5;241m=\u001B[39m GravityDataset(partition\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, dataset_name\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mnbody_name,\n\u001B[0;32m      6\u001B[0m                                max_samples\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mmax_samples, neighbours\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mneighbours, target\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mtarget)\n\u001B[0;32m      8\u001B[0m dataset_train\u001B[38;5;241m.\u001B[39mplot_energy_statistics()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'importlib' is not defined"
     ]
    }
   ],
   "source": [
    "import datasets.nbody.dataset_gravity as dataset_gravity\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "\n",
    "importlib.reload(dataset_gravity)\n",
    "\n",
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)\n",
    "\n",
    "dataset_train.plot_energy_statistics()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:31:06.275924Z",
     "start_time": "2024-03-18T09:31:06.244412Z"
    }
   },
   "id": "30beb88552206e1",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check whether the inference yields the same result as during the training\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb8023bceaf3b30"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch avg loss: 0.00782\n",
      "0.007820523008358886\n"
     ]
    }
   ],
   "source": [
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "dataset_val = GravityDataset(partition='val', dataset_name=args.nbody_name,\n",
    "                             neighbours=args.neighbours, target=args.target)\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "dataset_test = GravityDataset(partition='test', dataset_name=args.nbody_name,\n",
    "                              neighbours=args.neighbours, target=args.target)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "loaders = {\"train\": loader_train,\n",
    "           # \"valid\": loader_val,\n",
    "           # \"test\": loader_test,\n",
    "           }\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "tartets_across_sims = []\n",
    "predicted_data_across_sims = []\n",
    "for name, loader in loaders.items():\n",
    "    res = {'dataset': \"test\", 'loss': 0, 'counter': 0}\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        batch_size, n_nodes, _ = data[0].size()\n",
    "        data = [d.to(device) for d in data]\n",
    "        data = [d.view(-1, d.size(2)) for d in data]\n",
    "        loc, vel, force, mass, y = data\n",
    "\n",
    "        graph = Data(pos=loc, vel=vel, force=force, mass=mass, y=y)\n",
    "        batch = torch.arange(0, batch_size)\n",
    "        graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "        graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "\n",
    "        graph = transform(graph)  # Add O3 attributes\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        tartets_across_sims.append(graph.y)\n",
    "        pred = model(graph)\n",
    "        predicted_data_across_sims.append(pred)\n",
    "\n",
    "        loss = criterion(pred, graph.y)\n",
    "\n",
    "        #print(\"loss:\", loss.item() * batch_size)\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "\n",
    "        #break\n",
    "\n",
    "    print('%s epoch avg loss: %.5f' % (loader.dataset.partition, res['loss'] / res['counter']))\n",
    "\n",
    "    print(res['loss'] / res['counter'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T14:25:45.914567Z",
     "start_time": "2024-03-15T14:25:41.258317Z"
    }
   },
   "id": "f91b48e23472966b",
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
