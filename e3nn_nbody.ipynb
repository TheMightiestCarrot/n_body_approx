{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T12:54:26.188316300Z",
     "start_time": "2024-02-08T12:54:24.042440200Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mut\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_scatter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m scatter\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me3nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m o3, nn\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me3nn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmath\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m soft_one_hot_linspace\n",
      "File \u001B[1;32m~\\.conda\\envs\\n_body_approx\\lib\\site-packages\\torch_scatter\\__init__.py:16\u001B[0m\n\u001B[0;32m     14\u001B[0m spec \u001B[38;5;241m=\u001B[39m cuda_spec \u001B[38;5;129;01mor\u001B[39;00m cpu_spec\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 16\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBUILD_DOCS\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find module \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlibrary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_cpu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     19\u001B[0m                       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mosp\u001B[38;5;241m.\u001B[39mdirname(\u001B[38;5;18m__file__\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\n_body_approx\\lib\\site-packages\\torch\\_ops.py:933\u001B[0m, in \u001B[0;36m_Ops.load_library\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m    928\u001B[0m path \u001B[38;5;241m=\u001B[39m _utils_internal\u001B[38;5;241m.\u001B[39mresolve_library_path(path)\n\u001B[0;32m    929\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dl_open_guard():\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;66;03m# Import the shared library into the process, thus running its\u001B[39;00m\n\u001B[0;32m    931\u001B[0m     \u001B[38;5;66;03m# static (global) initialization code in order to register custom\u001B[39;00m\n\u001B[0;32m    932\u001B[0m     \u001B[38;5;66;03m# operators with the JIT.\u001B[39;00m\n\u001B[1;32m--> 933\u001B[0m     \u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCDLL\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaded_libraries\u001B[38;5;241m.\u001B[39madd(path)\n",
      "File \u001B[1;32m~\\.conda\\envs\\n_body_approx\\lib\\ctypes\\__init__.py:373\u001B[0m, in \u001B[0;36mCDLL.__init__\u001B[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001B[0m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_FuncPtr \u001B[38;5;241m=\u001B[39m _FuncPtr\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 373\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43m_dlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m handle\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import utils as ut\n",
    "import importlib\n",
    "from torch_scatter import scatter\n",
    "from e3nn import o3, nn\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "importlib.reload(ut)\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "N = 5  # Number of particles\n",
    "tEnd = 10.0  # time at which simulation ends\n",
    "dt = 0.01  # timestep\n",
    "softening = 0.15  # softening length\n",
    "G = 1.0  # Newton's Gravitational Constant\n",
    "boxSize = 1.0\n",
    "mass_coef = 10.0\n",
    "dims = 3\n",
    "LOG_WANDB = False\n",
    "\n",
    "hparams = {\n",
    "    'N': N,  # Number of particles\n",
    "    'tEnd': tEnd,  # Time at which simulation ends\n",
    "    'dt': dt,  # Timestep\n",
    "    'G': G,  # Newton's Gravitational Constant\n",
    "    'boxSize': boxSize,  # Size of the simulation box\n",
    "    'mass_coef': mass_coef  # Mass coefficient\n",
    "}\n",
    "\n",
    "combined_data = ut.simulate_gravitational_system(seed_value, N, tEnd, dt, softening, G, boxSize, mass_coef, dims=dims,\n",
    "                                                 init_boxsize=boxSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs_np, targets_np = ut.process_data(combined_data, dims=dims)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T12:49:54.406295600Z"
    }
   },
   "id": "ed042051925a95fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cf19a84028e90f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Convolution(torch.nn.Module):\n",
    "    def __init__(self, irreps_in, irreps_sh, irreps_out, num_neighbors, hidden_layer=256, embedding_dim=10) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "        tp = o3.FullyConnectedTensorProduct(\n",
    "            irreps_in1=irreps_in,\n",
    "            irreps_in2=irreps_sh,\n",
    "            irreps_out=irreps_out,\n",
    "            internal_weights=False,\n",
    "            shared_weights=False,\n",
    "        )\n",
    "        self.fc = o3.FullyConnectedNet([embedding_dim, hidden_layer, tp.weight_numel], torch.relu)\n",
    "        self.tp = tp\n",
    "        self.irreps_out = self.tp.irreps_out\n",
    "\n",
    "    def forward(self, node_features, edge_src, edge_dst, edge_attr, edge_scalars) -> torch.Tensor:\n",
    "        weight = self.fc(edge_scalars)\n",
    "        edge_features = self.tp(node_features[edge_src], edge_attr, weight)\n",
    "        node_features = scatter(edge_features, edge_dst, dim=0).div(self.num_neighbors ** 0.5)\n",
    "        return node_features\n",
    "\n",
    "\n",
    "class NbodyConv(torch.nn.Module):\n",
    "    def __init__(self, l=2, hidden_layers=256, max_radius=None, num_basis=10) -> None:\n",
    "        super().__init__()\n",
    "        self.irreps_sh: o3.Irreps = o3.Irreps.spherical_harmonics(l)\n",
    "        self.irreps_input = o3.Irreps(\"2x1o\")\n",
    "        self.irreps_output = o3.Irreps(\"2x1o\")\n",
    "        self.max_radius = max_radius\n",
    "        self.num_basis = num_basis\n",
    "        self.hidden_layers = hidden_layers\n",
    "\n",
    "        self.tensor_product = o3.FullyConnectedTensorProduct(\n",
    "            self.irreps_input,\n",
    "            self.irreps_sh,\n",
    "            self.irreps_output,\n",
    "            shared_weights=False)\n",
    "        \n",
    "        self.conv = Convolution(self.irreps_input, self.irreps_sh, self.irreps_output, N-1, hidden_layer=self.hidden_layers, embedding_dim=num_basis)\n",
    "        self.gate = nn.Gate(\n",
    "            \"16x0e + 16x0o\",\n",
    "            [torch.relu, torch.abs],  # scalar\n",
    "            \"8x0e + 8x0o + 8x0e + 8x0o\",\n",
    "            [torch.relu, torch.tanh, torch.relu, torch.tanh],  # gates (scalars)\n",
    "            \"16x1o + 16x1e\",  # gated tensors, num_irreps has to match with gates\n",
    "        )\n",
    "\n",
    "    def forward(self, data) -> torch.Tensor:\n",
    "        num_nodes = N\n",
    "        num_neighbors = num_nodes - 1\n",
    "        edge_src, edge_dst = data.edge_index\n",
    "\n",
    "        spherical_harmonics = o3.spherical_harmonics(self.irreps_sh, data.edge_vec, normalize=True,\n",
    "                                                     normalization='component')\n",
    "\n",
    "        x = self.conv(data.x, edge_src, edge_dst, spherical_harmonics, data.edge_attr)\n",
    "        \n",
    "        #x = self.gate(x)        \n",
    "        x = self.conv(data.x, edge_src, edge_dst, spherical_harmonics, data.edge_attr)\n",
    "        return scatter(x, data.batch, dim=0).div(num_nodes**0.5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T12:49:54.414298900Z",
     "start_time": "2024-02-08T12:49:54.408299400Z"
    }
   },
   "id": "df4e8cbe47ed0785"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T12:49:54.409304800Z"
    }
   },
   "id": "575008e353a638c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca31e8532816cb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_fully_connected_data_with_edge_features(node_features, positions, targets, max_radius, num_basis):\n",
    "    num_nodes = node_features.size(0)\n",
    "    device = node_features.device\n",
    "\n",
    "    # Generate fully connected edge_index for num_nodes\n",
    "    row = torch.arange(num_nodes, device=device).repeat_interleave(num_nodes)\n",
    "    col = torch.arange(num_nodes, device=device).repeat(num_nodes)\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    # Avoid self-loops\n",
    "    edge_index = edge_index[:, row != col]\n",
    "\n",
    "    # Calculate edge features\n",
    "    edge_vec = positions[edge_index[0]] - positions[edge_index[1]]\n",
    "    edge_features = soft_one_hot_linspace(\n",
    "        edge_vec.norm(dim=1),\n",
    "        0.0,\n",
    "        max_radius,\n",
    "        num_basis,\n",
    "        basis='smooth_finite',\n",
    "        cutoff=True\n",
    "    ).mul(num_basis ** 0.5)\n",
    "\n",
    "    y = targets.detach().to(device).to(torch.float32)\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=y, edge_vec=edge_vec)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T12:49:54.411301800Z"
    }
   },
   "id": "b70ba9d9297edcbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "d = (boxSize**2 + boxSize**2 + boxSize**2)**0.5\n",
    "max_radius = d\n",
    "num_basis = 10\n",
    "\n",
    "inputs_tensor = torch.tensor(inputs_np, dtype=torch.float32)\n",
    "targets_tensor = torch.tensor(targets_np, dtype=torch.float32)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for index, simulation_step_graph in enumerate(inputs_tensor):\n",
    "    node_features = simulation_step_graph\n",
    "    positions = node_features[..., :dims]\n",
    "    targets = targets_tensor[index, ...]\n",
    "\n",
    "    data = create_fully_connected_data_with_edge_features(node_features, positions, targets,\n",
    "                                                          max_radius=max_radius, num_basis=num_basis)\n",
    "    data_list.append(data)\n",
    "\n",
    "data_loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T12:49:54.413298600Z"
    }
   },
   "id": "ac9a5af64e822a70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_loader.dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T12:49:54.414298900Z",
     "start_time": "2024-02-08T12:49:54.414298900Z"
    }
   },
   "id": "71a63a5cc2f50682"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_loader.dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a228aee1471dccda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34ce8d405f1ed5d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = NbodyConv()\n",
    "print(\"wtf\")\n",
    "for batch in data_loader:\n",
    "    # batch.x: current state node features\n",
    "    # batch.edge_index: edges for fully connected graph\n",
    "    # batch.edge_attr: edge features\n",
    "    # batch.y: labels for the next state of the simulation\n",
    "    outputs = model(batch)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "605a89c21a058407"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "255b2d6bbf1e822d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = NbodyConv()\n",
    "num_epochs = 10\n",
    "lr = 1e-2\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_metrics = {\n",
    "        \"loss\": 0, \"loss_pos\": 0, \"loss_vel\": 0,\n",
    "        \"perc_error_pos\": 0, \"perc_error_vel\": 0, \"perc_error_pos_vs_vel_l1\": 0, \"perc_error_pos_vs_vel_l2\": 0\n",
    "    }\n",
    "    num_batches = 0\n",
    "    for batch in data_loader:\n",
    "        inputs, targets = batch  # Adjust based on your data loading method\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_pos = outputs[..., :dims]\n",
    "            target_pos = targets[..., :dims]\n",
    "\n",
    "            predicted_vel = outputs[..., dims:]\n",
    "            target_vel = targets[..., dims:]\n",
    "\n",
    "            loss_pos = criterion(predicted_pos, target_pos)\n",
    "            loss_vel = criterion(predicted_vel, target_vel)\n",
    "\n",
    "            # Calculate percentage errors\n",
    "            perc_error_pos = (torch.norm(predicted_pos - target_pos, dim=1) /\n",
    "                              torch.norm(target_pos, dim=1)).mean() * 100\n",
    "\n",
    "            perc_error_vel = (torch.norm(predicted_vel - target_vel, dim=1) /\n",
    "                              torch.norm(target_vel, dim=1)).mean() * 100\n",
    "\n",
    "            perc_error_pos_vs_vel_l1 = (torch.abs(predicted_pos - target_pos).mean() /\n",
    "                                        torch.norm(target_vel, dim=1)).mean() * 100\n",
    "\n",
    "            perc_error_pos_vs_vel_l2 = (torch.norm(predicted_pos - target_pos, dim=1) /\n",
    "                                        torch.norm(target_vel, dim=1)).mean() * 100\n",
    "\n",
    "            total_metrics[\"loss\"] += loss.item()\n",
    "            total_metrics[\"loss_pos\"] += loss_pos.item()\n",
    "            total_metrics[\"loss_vel\"] += loss_vel.item()\n",
    "            total_metrics[\"perc_error_pos\"] += perc_error_pos.item()\n",
    "            total_metrics[\"perc_error_vel\"] += perc_error_vel.item()\n",
    "            total_metrics[\"perc_error_pos_vs_vel_l1\"] += perc_error_pos_vs_vel_l1.item()\n",
    "            total_metrics[\"perc_error_pos_vs_vel_l2\"] += perc_error_pos_vs_vel_l2.item()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        avg_metrics = {k: v / num_batches for k, v in total_metrics.items()}\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}], avg_both: {avg_metrics['loss']:.5f}, avg_pos: {avg_metrics['loss_pos']: .5f}, avg_vel: {avg_metrics['loss_vel']: .5f}, perc_pos: {avg_metrics['perc_error_pos']: .5f}%, perc_vel: {avg_metrics['perc_error_vel']: .5f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1cb832c1703f66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
