{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "def create_argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Run parameters\n",
    "    parser.add_argument('--epochs', type=int, default=1000,\n",
    "                        help='number of epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='Batch size. Does not scale with number of gpus.')\n",
    "    parser.add_argument('--lr', type=float, default=5e-4,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-8,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--print', type=int, default=100,\n",
    "                        help='print interval')\n",
    "    parser.add_argument('--log', type=bool, default=False,\n",
    "                        help='logging flag')\n",
    "    parser.add_argument('--num_workers', type=int, default=4,\n",
    "                        help='Num workers in dataloader')\n",
    "    parser.add_argument('--save_dir', type=str, default=\"saved models\",\n",
    "                        help='Directory in which to save models')\n",
    "\n",
    "    # Data parameters\n",
    "    parser.add_argument('--dataset', type=str, default=\"qm9\",\n",
    "                        help='Data set')\n",
    "    parser.add_argument('--root', type=str, default=\"datasets\",\n",
    "                        help='Data set location')\n",
    "    parser.add_argument('--download', type=bool, default=False,\n",
    "                        help='Download flag')\n",
    "\n",
    "    # QM9 parameters\n",
    "    parser.add_argument('--target', type=str, default=\"alpha\",\n",
    "                        help='Target value, also used for gravity dataset [pos, force]')\n",
    "    parser.add_argument('--radius', type=float, default=2,\n",
    "                        help='Radius (Angstrom) between which atoms to add links.')\n",
    "    parser.add_argument('--feature_type', type=str, default=\"one_hot\",\n",
    "                        help='Type of input feature: one-hot, or Cormorants charge thingy')\n",
    "\n",
    "    # Nbody parameters:\n",
    "    parser.add_argument('--nbody_name', type=str, default=\"nbody_small\",\n",
    "                        help='Name of nbody data [nbody, nbody_small]')\n",
    "    parser.add_argument('--max_samples', type=int, default=3000,\n",
    "                        help='Maximum number of samples in nbody dataset')\n",
    "    parser.add_argument('--time_exp', type=bool, default=False,\n",
    "                        help='Flag for timing experiment')\n",
    "    parser.add_argument('--test_interval', type=int, default=5,\n",
    "                        help='Test every test_interval epochs')\n",
    "    parser.add_argument('--n_nodes', type=int, default=5,\n",
    "                        help='How many nodes are in the graph.')\n",
    "\n",
    "    # Gravity parameters:\n",
    "    parser.add_argument('--neighbours', type=int, default=6,\n",
    "                        help='Number of connected nearest neighbours')\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', type=str, default=\"segnn\",\n",
    "                        help='Model name')\n",
    "    parser.add_argument('--hidden_features', type=int, default=128,\n",
    "                        help='max degree of hidden rep')\n",
    "    parser.add_argument('--lmax_h', type=int, default=2,\n",
    "                        help='max degree of hidden rep')\n",
    "    parser.add_argument('--lmax_attr', type=int, default=3,\n",
    "                        help='max degree of geometric attribute embedding')\n",
    "    parser.add_argument('--subspace_type', type=str, default=\"weightbalanced\",\n",
    "                        help='How to divide spherical harmonic subspaces')\n",
    "    parser.add_argument('--layers', type=int, default=7,\n",
    "                        help='Number of message passing layers')\n",
    "    parser.add_argument('--norm', type=str, default=\"instance\",\n",
    "                        help='Normalisation type [instance, batch]')\n",
    "    parser.add_argument('--pool', type=str, default=\"avg\",\n",
    "                        help='Pooling type type [avg, sum]')\n",
    "    parser.add_argument('--conv_type', type=str, default=\"linear\",\n",
    "                        help='Linear or non-linear aggregation of local information in SEConv')\n",
    "\n",
    "    # Parallel computing stuff\n",
    "    parser.add_argument('-g', '--gpus', default=0, type=int,\n",
    "                        help='number of gpus to use (assumes all are on one node)')\n",
    "\n",
    "    return parser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:52:51.198675Z",
     "start_time": "2024-03-12T11:52:51.172689Z"
    }
   },
   "id": "7edc8a8761e1b07b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinKaras(AI)\\.conda\\envs\\n_body_approx_3_10\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from datasets.nbody.dataset_gravity import GravityDataset\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(sys.executable)\n",
    "\n",
    "import utils.nbody_utils as ut\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "run = os.path.join(\"segnn_runs\", \"2024-03-11 16-42_gravity_segnn\")\n",
    "\n",
    "models = glob.glob(run + \"/\" + '*.pth')\n",
    "if len(models) > 1:\n",
    "    print(\"MORE MODELS FOUND IN THE DIR, LOADING THE FIRST:\", models[0])\n",
    "\n",
    "model = torch.load(models[0], map_location=device)\n",
    "\n",
    "sys.argv = [\n",
    "    'main.py', '--dataset=gravity', '--epochs=5', '--max_samples=3000',\n",
    "    '--model=segnn', '--lmax_h=1', '--lmax_attr=1', '--layers=4',\n",
    "    '--hidden_features=64', '--subspace_type=weightbalanced', '--norm=none',\n",
    "    '--batch_size=100', '--gpu=1', '--weight_decay=1e-12', '--target=pos'\n",
    "]\n",
    "parser = create_argparser()\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:52:52.813873Z",
     "start_time": "2024-03-12T11:52:52.593800Z"
    }
   },
   "id": "49eba1514facfe10",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "simulation_index = 0\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "output_dims = 3\n",
    "batch_size = 50\n",
    "n_nodes = 5\n",
    "t_delta = 2\n",
    "\n",
    "loc = torch.from_numpy(loc[simulation_index]).view(-1, output_dims)\n",
    "vel = torch.from_numpy(vel[simulation_index]).view(-1, output_dims)\n",
    "force = torch.from_numpy(force[simulation_index]).view(-1, output_dims)\n",
    "mass = mass[simulation_index].repeat(batch_size, 1)\n",
    "data = [loc, vel, force, mass]\n",
    "\n",
    "if args.target == 'pos':\n",
    "    y = loc\n",
    "else:\n",
    "    y = force\n",
    "\n",
    "data = [d.to(device) for d in data]\n",
    "loc, vel, force, mass = data\n",
    "\n",
    "graph = Data(pos=loc, vel=vel, force=force, mass=mass, y=y)\n",
    "batch = torch.arange(0, batch_size)\n",
    "graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "\n",
    "graph = transform(graph)  # Add O3 attributes\n",
    "graph = graph.to(device)\n",
    "pred = model(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T12:28:58.893948Z",
     "start_time": "2024-03-12T12:28:58.784360Z"
    }
   },
   "id": "f82fbc7582a0c32e",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import utils.nbody_utils as ut\n",
    "%matplotlib qt\n",
    "\n",
    "particle_index = 4\n",
    "boxSize = 5\n",
    "\n",
    "predicted_data = pred.view(batch_size, n_nodes, output_dims).detach().cpu().numpy()\n",
    "loc_orig = loc.view(batch_size, n_nodes, output_dims)\n",
    "\n",
    "targets = []\n",
    "for i in range(0, batch_size - t_delta):\n",
    "    targets.append(loc_orig[i + t_delta, :, :])\n",
    "\n",
    "targets_np = np.array(targets)\n",
    "\n",
    "ut.plot_trajectory(targets_np[: (batch_size - t_delta), ...], predicted_data, particle_index=particle_index, loggers=[],\n",
    "                   epoch=1,\n",
    "                   dims=output_dims)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T12:31:54.032266Z",
     "start_time": "2024-03-12T12:31:53.980740Z"
    }
   },
   "id": "5deb9d99498406f2",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "50"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_data.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T12:20:13.630683Z",
     "start_time": "2024-03-12T12:20:13.613686Z"
    }
   },
   "id": "26a4842de13d5e41",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(ut)\n",
    "\n",
    "sim_steps = batch_size - t_delta\n",
    "ut.interactive_trajectory_plot_all_particles_3d(targets_np[0:sim_steps, ...], predicted_data[0:sim_steps, ...],\n",
    "                                                particle_index,\n",
    "                                                boxSize=boxSize, dims=output_dims, offline_plot=False, loggers=[],\n",
    "                                                video_tag=f\"One step prediction of a particle {particle_index}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T15:35:57.308959Z",
     "start_time": "2024-03-12T15:35:37.182544Z"
    }
   },
   "id": "c0588a3fa027f2b0",
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre istotu overenie, ci pri inferenci dosiahnem rovnaky result ako pocas treningu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb8023bceaf3b30"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch avg loss: 0.00782\n",
      "0.007820523008358888\n"
     ]
    }
   ],
   "source": [
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "dataset_val = GravityDataset(partition='val', dataset_name=args.nbody_name,\n",
    "                             neighbours=args.neighbours, target=args.target)\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "dataset_test = GravityDataset(partition='test', dataset_name=args.nbody_name,\n",
    "                              neighbours=args.neighbours, target=args.target)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "loaders = {\"train\": loader_train,\n",
    "           # \"valid\": loader_val,\n",
    "           # \"test\": loader_test,\n",
    "           }\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "tartets_across_sims = []\n",
    "predicted_data_across_sims = []\n",
    "for name, loader in loaders.items():\n",
    "    res = {'dataset': \"test\", 'loss': 0, 'counter': 0}\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        batch_size, n_nodes, _ = data[0].size()\n",
    "        data = [d.to(device) for d in data]\n",
    "        data = [d.view(-1, d.size(2)) for d in data]\n",
    "        loc, vel, force, mass, y = data\n",
    "\n",
    "        graph = Data(pos=loc, vel=vel, force=force, mass=mass, y=y)\n",
    "        batch = torch.arange(0, batch_size)\n",
    "        graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "        graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "\n",
    "        graph = transform(graph)  # Add O3 attributes\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        tartets_across_sims.append(graph.y)\n",
    "        pred = model(graph)\n",
    "        predicted_data_across_sims.append(pred)\n",
    "\n",
    "        loss = criterion(pred, graph.y)\n",
    "\n",
    "        #print(\"loss:\", loss.item() * batch_size)\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "\n",
    "        #break\n",
    "\n",
    "    print('%s epoch avg loss: %.5f' % (loader.dataset.partition, res['loss'] / res['counter']))\n",
    "\n",
    "    print(res['loss'] / res['counter'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T15:54:22.742068Z",
     "start_time": "2024-03-12T15:54:18.936207Z"
    }
   },
   "id": "f91b48e23472966b",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6d2ef4f42f5c1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0642, dtype=torch.float64, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T15:38:44.811698Z",
     "start_time": "2024-03-12T15:38:44.802709Z"
    }
   },
   "id": "184950540d18e280",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m target_batch \u001B[38;5;241m=\u001B[39m tartets_across_sims[batch_index]\u001B[38;5;241m.\u001B[39mview(args\u001B[38;5;241m.\u001B[39mbatch_size, bodies, dims)\n\u001B[0;32m     10\u001B[0m predicted_batch \u001B[38;5;241m=\u001B[39m predicted_data_across_sims[batch_index]\u001B[38;5;241m.\u001B[39mview(args\u001B[38;5;241m.\u001B[39mbatch_size, bodies, dims)\n\u001B[1;32m---> 12\u001B[0m \u001B[43mut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minteractive_trajectory_plot_all_particles_3d_traceless\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredicted_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                                                \u001B[49m\u001B[43mparticle_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                                                \u001B[49m\u001B[43mboxSize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffline_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\n_body_approx\\utils\\nbody_utils.py:1124\u001B[0m, in \u001B[0;36minteractive_trajectory_plot_all_particles_3d_traceless\u001B[1;34m(actual_data, predicted_data, particle_index, boxSize, dims, offline_plot)\u001B[0m\n\u001B[0;32m   1120\u001B[0m             predicted_line\u001B[38;5;241m.\u001B[39mset_3d_properties(predicted_data[start_step:time_step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, particle_index, \u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m   1122\u001B[0m     fig\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mdraw_idle()\n\u001B[1;32m-> 1124\u001B[0m \u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1125\u001B[0m slider\u001B[38;5;241m.\u001B[39mon_changed(update)\n\u001B[0;32m   1126\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow(block\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\DataspellProjects\\n_body_approx\\utils\\nbody_utils.py:1120\u001B[0m, in \u001B[0;36minteractive_trajectory_plot_all_particles_3d_traceless.<locals>.update\u001B[1;34m(val)\u001B[0m\n\u001B[0;32m   1117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pi \u001B[38;5;241m==\u001B[39m particle_index:\n\u001B[0;32m   1118\u001B[0m         predicted_line\u001B[38;5;241m.\u001B[39mset_data(predicted_data[start_step:time_step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, particle_index, \u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m   1119\u001B[0m                                 predicted_data[start_step:time_step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, particle_index, \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m-> 1120\u001B[0m         \u001B[43mpredicted_line\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_3d_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredicted_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstart_step\u001B[49m\u001B[43m:\u001B[49m\u001B[43mtime_step\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparticle_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1122\u001B[0m fig\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mdraw_idle()\n",
      "File \u001B[1;32m~\\.conda\\envs\\n_body_approx_3_10\\lib\\site-packages\\mpl_toolkits\\mplot3d\\art3d.py:226\u001B[0m, in \u001B[0;36mLine3D.set_3d_properties\u001B[1;34m(self, zs, zdir)\u001B[0m\n\u001B[0;32m    224\u001B[0m xs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_xdata()\n\u001B[0;32m    225\u001B[0m ys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_ydata()\n\u001B[1;32m--> 226\u001B[0m zs \u001B[38;5;241m=\u001B[39m \u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_to_unmasked_float_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mzs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mravel()\n\u001B[0;32m    227\u001B[0m zs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbroadcast_to(zs, \u001B[38;5;28mlen\u001B[39m(xs))\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verts3d \u001B[38;5;241m=\u001B[39m juggle_axes(xs, ys, zs, zdir)\n",
      "File \u001B[1;32m~\\.conda\\envs\\n_body_approx_3_10\\lib\\site-packages\\matplotlib\\cbook.py:1345\u001B[0m, in \u001B[0;36m_to_unmasked_float_array\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1343\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39masarray(x, \u001B[38;5;28mfloat\u001B[39m)\u001B[38;5;241m.\u001B[39mfilled(np\u001B[38;5;241m.\u001B[39mnan)\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\n_body_approx_3_10\\lib\\site-packages\\torch\\_tensor.py:1064\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m   1063\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1064\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(ut)\n",
    "\n",
    "batch_index = 0\n",
    "bodies = 5\n",
    "dims = 3\n",
    "\n",
    "target_batch = tartets_across_sims[batch_index].view(args.batch_size, bodies, dims)\n",
    "predicted_batch = predicted_data_across_sims[batch_index].view(args.batch_size, bodies, dims)\n",
    "\n",
    "ut.interactive_trajectory_plot_all_particles_3d_traceless(target_batch, predicted_batch,\n",
    "                                                particle_index,\n",
    "                                                boxSize=100, dims=output_dims, offline_plot=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T15:24:22.893112Z",
     "start_time": "2024-03-12T15:24:22.746581Z"
    }
   },
   "id": "33e7d19bab03b8ed",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'hist'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtarget_batch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhist\u001B[49m()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'hist'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T15:24:35.248073Z",
     "start_time": "2024-03-12T15:24:35.213070Z"
    }
   },
   "id": "f235c6807b93f89b",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ -1.9480,   4.8764,  -3.8974],\n         [ -1.8426,  -5.9129,   5.0681],\n         [  7.4131,   4.2478,   1.9860],\n         [ -0.1863,  -1.4185,  -0.5329],\n         [ -2.0059,   0.1075,  -0.7064]],\n\n        [[  2.9195,   3.6957,   3.0300],\n         [ -2.9632,  -0.1848,  -0.3156],\n         [  1.7131,   4.4300,  -1.0551],\n         [ -2.2534,  -3.8965,  -2.4178],\n         [  0.0294,  -2.2210,   0.9493]],\n\n        [[  1.5798,   0.1219,   2.5410],\n         [  0.0279,  -1.6298,  -5.9386],\n         [  0.6670,   0.1946,   2.2185],\n         [  0.8986,   1.5189,  -1.6213],\n         [ -1.1588,  -0.3964,  -2.5214]],\n\n        ...,\n\n        [[  4.8291,  -0.8865,   2.9310],\n         [-12.4625,  -2.1715,  -9.0458],\n         [  2.9522,   0.1313,   3.3234],\n         [  3.9450,   2.3900,   0.9518],\n         [  4.2906,  -0.4960,   3.0844]],\n\n        [[ -1.5818,   0.1036,   0.5068],\n         [  0.6517,   2.1105,  -2.2905],\n         [  0.2159,  -1.8116,  -5.1037],\n         [ -1.4800,   0.1378,   0.6373],\n         [  4.5307,  -1.8275,   3.6951]],\n\n        [[ -0.4165,  -0.4150,  -0.3874],\n         [ -0.6151,  -1.0237,   0.3192],\n         [ -0.3531,  -0.3955,  -0.4939],\n         [  0.1913,  -0.4544,  -0.7603],\n         [  0.1185,  -0.4286,  -0.0206]]], dtype=torch.float64,\n       grad_fn=<ViewBackward0>)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T15:10:34.395866Z",
     "start_time": "2024-03-12T15:10:34.386865Z"
    }
   },
   "id": "f2d6ce12a4ce0963",
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
