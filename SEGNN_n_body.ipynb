{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinKaras(AI)\\.conda\\envs\\n_body_approx_3_10\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from utils import segnn_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from datasets.nbody.dataset_gravity import GravityDataset\n",
    "\n",
    "sys.argv = [\n",
    "    'main.py', '--dataset=gravity', '--epochs=5', '--max_samples=3000',\n",
    "    '--model=segnn', '--lmax_h=1', '--lmax_attr=1', '--layers=4',\n",
    "    '--hidden_features=64', '--subspace_type=weightbalanced', '--norm=none',\n",
    "    '--batch_size=100', '--gpu=1', '--weight_decay=1e-12', '--target=pos'\n",
    "]\n",
    "parser = segnn_utils.create_argparser()\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(sys.executable)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "run = os.path.join(\"segnn_runs\", \"2024-03-11 16-42_gravity_segnn\")\n",
    "\n",
    "models = glob.glob(run + \"/\" + '*.pth')\n",
    "if len(models) > 1:\n",
    "    print(\"MORE MODELS FOUND IN THE DIR, LOADING THE FIRST:\", models[0])\n",
    "\n",
    "model = torch.load(models[0], map_location=device)\n",
    "\n",
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:19:57.730983Z",
     "start_time": "2024-03-18T09:19:52.941247Z"
    }
   },
   "id": "49eba1514facfe10",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting prediction from batches, where a batch is all steps of a single simulation\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9cacda1635bda3c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinKaras(AI)\\.conda\\envs\\n_body_approx_3_10\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "simulation_index = 0\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "output_dims = loc.shape[-1]\n",
    "batch_size = loc.shape[-3]\n",
    "n_nodes = loc.shape[-2]\n",
    "t_delta = 2\n",
    "\n",
    "loc = torch.from_numpy(loc[simulation_index]).view(-1, output_dims)\n",
    "vel = torch.from_numpy(vel[simulation_index]).view(-1, output_dims)\n",
    "force = torch.from_numpy(force[simulation_index]).view(-1, output_dims)\n",
    "mass = torch.from_numpy(mass[simulation_index]).repeat(batch_size, 1)\n",
    "data = [loc, vel, force, mass]\n",
    "\n",
    "if args.target == 'pos':\n",
    "    y = loc\n",
    "else:\n",
    "    y = force\n",
    "\n",
    "data = [d.to(device) for d in data]\n",
    "loc, vel, force, mass = data\n",
    "\n",
    "graph = Data(pos=loc, vel=vel, force=force, mass=mass, y=y)\n",
    "batch = torch.arange(0, batch_size)\n",
    "graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "\n",
    "graph = transform(graph)  # Add O3 attributes\n",
    "graph = graph.to(device)\n",
    "batch_prediction = model(graph).cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:19:59.315949Z",
     "start_time": "2024-03-18T09:19:57.731984Z"
    }
   },
   "id": "784c2d52f9547f57",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Batch simulation where batch is [simulations x steps x nodes], be careful this requires lots of memory \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97387de436a13785"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "max_simulations = 500\n",
    "\n",
    "output_dims = loc.shape[-1]\n",
    "batch_size = loc.shape[-3]\n",
    "n_nodes = loc.shape[-2]\n",
    "t_delta = 2\n",
    "\n",
    "loc = torch.from_numpy(loc)\n",
    "vel = torch.from_numpy(vel)\n",
    "force = torch.from_numpy(force)\n",
    "mass = torch.from_numpy(mass)\n",
    "\n",
    "if args.target == 'pos':\n",
    "    y = loc\n",
    "else:\n",
    "    y = force\n",
    "\n",
    "graphs = []\n",
    "for i in range(max_simulations):\n",
    "    mss = mass[i].repeat(batch_size, 1)\n",
    "    data_i = Data(pos=loc[i].view(-1, output_dims), vel=vel[i].view(-1, output_dims),\n",
    "                  force=force[i].view(-1, output_dims), mass=mss, y=y[i].view(-1, output_dims))\n",
    "    data_i.batch = torch.arange(batch_size).repeat_interleave(n_nodes).long()\n",
    "    data_i.edge_index = knn_graph(data_i.pos, args.neighbours, data_i.batch)\n",
    "    data_i = transform(data_i)\n",
    "    graphs.append(data_i)\n",
    "\n",
    "batched_graph = Batch.from_data_list(graphs)\n",
    "batched_graph = batched_graph.to(device)\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "batched_graph = Batch.from_data_list(graphs)\n",
    "batched_graph = batched_graph.to(device)\n",
    "pred = model(batched_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T09:06:58.059547Z"
    }
   },
   "id": "f82fbc7582a0c32e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stepwise simulation\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ecc2b374d75d8a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from datasets.nbody.train_gravity import O3Transform\n",
    "\n",
    "transform = O3Transform(args.lmax_attr)\n",
    "\n",
    "simulation_index = 0\n",
    "\n",
    "loc, vel, force, mass = dataset_train.data\n",
    "\n",
    "output_dims = loc.shape[-1]\n",
    "n_nodes = loc.shape[-2]\n",
    "t_delta = 2\n",
    "\n",
    "# Assuming simulation_steps is defined or calculated from your dataset\n",
    "simulation_steps = len(loc[simulation_index])  # Or however you determine the number of steps\n",
    "stepwise_prediction = []\n",
    "for step in range(simulation_steps):\n",
    "    loc_step = torch.from_numpy(loc[simulation_index][step]).view(-1, output_dims).to(device)\n",
    "    vel_step = torch.from_numpy(vel[simulation_index][step]).view(-1, output_dims).to(device)\n",
    "    force_step = torch.from_numpy(force[simulation_index][step]).view(-1, output_dims).to(device)\n",
    "    mass_step = torch.tensor(mass[simulation_index], dtype=torch.float).repeat(n_nodes, 1).to(device)\n",
    "\n",
    "    if args.target == 'pos':\n",
    "        y_step = loc_step\n",
    "    else:\n",
    "        y_step = force_step\n",
    "\n",
    "    graph = Data(pos=loc_step, vel=vel_step, force=force_step, mass=mass_step, y=y_step)\n",
    "    # Since we're dealing with single steps, no need to batch\n",
    "    graph.edge_index = knn_graph(loc_step, args.neighbours)\n",
    "\n",
    "    graph = transform(graph)  # Add O3 attributes\n",
    "    graph = graph.to(device)\n",
    "    stepwise_prediction.append(model(graph).detach().numpy())\n",
    "\n",
    "stepwise_prediction = np.stack(stepwise_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:03:16.295150Z",
     "start_time": "2024-03-18T08:03:15.291933Z"
    }
   },
   "id": "e641cbc560754aa0",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Batch vs stepwise comparison\n",
    "they are identical"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb64fd108ccc6e05"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE_Batch': 4.053788708247991e-31, 'MSE_Stepwise': 4.053788708247991e-31, 'MSE_Difference': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def compare_predictions(batch_preds_np, stepwise_preds_np):\n",
    "    # Calculate MSE\n",
    "    mse_batch = mean_squared_error(batch_preds_np.reshape(-1, 3), stepwise_preds_np.reshape(-1, 3))\n",
    "    mse_stepwise = mean_squared_error(stepwise_preds_np.reshape(-1, 3), batch_preds_np.reshape(-1, 3))\n",
    "\n",
    "    return {\n",
    "        \"MSE_Batch\": mse_batch,\n",
    "        \"MSE_Stepwise\": mse_stepwise,\n",
    "        \"MSE_Difference\": abs(mse_batch - mse_stepwise)\n",
    "    }\n",
    "\n",
    "\n",
    "comparison_results = compare_predictions(batch_prediction, stepwise_prediction)\n",
    "\n",
    "print(comparison_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:06:31.843031Z",
     "start_time": "2024-03-18T08:06:31.832017Z"
    }
   },
   "id": "f2b3c6358162ed29",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot the whole simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1987cd9c25d516e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import utils.nbody_utils as ut\n",
    "%matplotlib qt\n",
    "\n",
    "particle_index = 4\n",
    "boxSize = 5\n",
    "\n",
    "loc_orig = loc.view(batch_size, n_nodes, output_dims)\n",
    "\n",
    "targets = []\n",
    "for i in range(0, batch_size - t_delta):\n",
    "    targets.append(loc_orig[i + t_delta, :, :])\n",
    "\n",
    "targets_np = np.array(targets)\n",
    "\n",
    "predicted_data = batch_prediction.reshape(batch_size, n_nodes, output_dims)\n",
    "\n",
    "ut.plot_trajectory(targets_np[: (batch_size - t_delta), ...], predicted_data, particle_index=particle_index,\n",
    "                   loggers=[],\n",
    "                   epoch=1,\n",
    "                   dims=output_dims)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:21:38.432174Z",
     "start_time": "2024-03-18T09:21:38.365175Z"
    }
   },
   "id": "5deb9d99498406f2",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interactive plot of the simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82efe104f68292eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sim_steps = batch_size - t_delta\n",
    "ut.interactive_trajectory_plot_all_particles_3d(targets_np[0:sim_steps, ...], predicted_data[0:sim_steps, ...],\n",
    "                                                particle_index,\n",
    "                                                boxSize=boxSize, dims=output_dims, offline_plot=False, loggers=[],\n",
    "                                                video_tag=f\"One step prediction of a particle {particle_index}\",\n",
    "                                                trace_length=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:21:46.877609Z",
     "start_time": "2024-03-18T09:21:40.893342Z"
    }
   },
   "id": "f3233e696295ba24",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnbody\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_gravity\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdataset_gravity\u001B[39;00m\n\u001B[0;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mimportlib\u001B[49m\u001B[38;5;241m.\u001B[39mreload(dataset_gravity)\n\u001B[0;32m      5\u001B[0m dataset_train \u001B[38;5;241m=\u001B[39m GravityDataset(partition\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, dataset_name\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mnbody_name,\n\u001B[0;32m      6\u001B[0m                                max_samples\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mmax_samples, neighbours\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mneighbours, target\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mtarget)\n\u001B[0;32m      8\u001B[0m dataset_train\u001B[38;5;241m.\u001B[39mplot_energy_statistics()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'importlib' is not defined"
     ]
    }
   ],
   "source": [
    "import datasets.nbody.dataset_gravity as dataset_gravity\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "importlib.reload(dataset_gravity)\n",
    "\n",
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)\n",
    "\n",
    "dataset_train.plot_energy_statistics()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:31:06.275924Z",
     "start_time": "2024-03-18T09:31:06.244412Z"
    }
   },
   "id": "30beb88552206e1",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check whether the inference yields the same result as during the training\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb8023bceaf3b30"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch avg loss: 0.00782\n",
      "0.007820523008358886\n"
     ]
    }
   ],
   "source": [
    "dataset_train = GravityDataset(partition='train', dataset_name=args.nbody_name,\n",
    "                               max_samples=args.max_samples, neighbours=args.neighbours, target=args.target)\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "dataset_val = GravityDataset(partition='val', dataset_name=args.nbody_name,\n",
    "                             neighbours=args.neighbours, target=args.target)\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "dataset_test = GravityDataset(partition='test', dataset_name=args.nbody_name,\n",
    "                              neighbours=args.neighbours, target=args.target)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "loaders = {\"train\": loader_train,\n",
    "           # \"valid\": loader_val,\n",
    "           # \"test\": loader_test,\n",
    "           }\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "tartets_across_sims = []\n",
    "predicted_data_across_sims = []\n",
    "for name, loader in loaders.items():\n",
    "    res = {'dataset': \"test\", 'loss': 0, 'counter': 0}\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        batch_size, n_nodes, _ = data[0].size()\n",
    "        data = [d.to(device) for d in data]\n",
    "        data = [d.view(-1, d.size(2)) for d in data]\n",
    "        loc, vel, force, mass, y = data\n",
    "\n",
    "        graph = Data(pos=loc, vel=vel, force=force, mass=mass, y=y)\n",
    "        batch = torch.arange(0, batch_size)\n",
    "        graph.batch = batch.repeat_interleave(n_nodes).long()\n",
    "        graph.edge_index = knn_graph(loc, args.neighbours, graph.batch)\n",
    "\n",
    "        graph = transform(graph)  # Add O3 attributes\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        tartets_across_sims.append(graph.y)\n",
    "        pred = model(graph)\n",
    "        predicted_data_across_sims.append(pred)\n",
    "\n",
    "        loss = criterion(pred, graph.y)\n",
    "\n",
    "        #print(\"loss:\", loss.item() * batch_size)\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "\n",
    "        #break\n",
    "\n",
    "    print('%s epoch avg loss: %.5f' % (loader.dataset.partition, res['loss'] / res['counter']))\n",
    "\n",
    "    print(res['loss'] / res['counter'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T14:25:45.914567Z",
     "start_time": "2024-03-15T14:25:41.258317Z"
    }
   },
   "id": "f91b48e23472966b",
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
